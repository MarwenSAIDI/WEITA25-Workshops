{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **COMGRA NLP TASK**"
      ],
      "metadata": {
        "id": "JMCYG-K8xM8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook trains a simple sentiment analysis model on the IMDB dataset using PyTorch. It performs the following tasks:\n",
        "\n",
        "1. Data Preparation: Defines functions to load and preprocess the IMDB data and a custom Dataset class that builds a vocabulary and converts text reviews into vector representations.\n",
        "2. Model Definition: Implements a simple feed-forward neural network for sentiment classification.\n",
        "3. Training Loop: Runs the training (and validation) loop, using a global step counter for monotonic training steps. In each batch, key tensors and gradients are recorded using Comgra.\n",
        "4. Testing & Finalization: Defines a prediction function to test the model on sample reviews and finalizes the Comgra recording.\n",
        "5. Comgra Server Launch: Starts a Comgra server to view the recorded training metrics (ideal for environments like Google Colab).\n",
        "\n"
      ],
      "metadata": {
        "id": "7Fj3Bcq5w1Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "!pip install comgra==0.11.5 --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjLgzXmHgknf",
        "outputId": "76ab1931-f755-4966-c39f-fd51547d61ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/92.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.3/229.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.2/810.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for comgra (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports all necessary libraries and sets up the computing device (using CUDA if available).**"
      ],
      "metadata": {
        "id": "T2dmxwp8xYi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import comgra\n",
        "from comgra.objects import DecisionMakerForRecordingsFrequencyPerType\n",
        "from comgra.recorder import ComgraRecorder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import subprocess\n",
        "import time\n",
        "from google.colab import output\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Device configuration: use CUDA if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJhna_4vxVcw",
        "outputId": "df3dbeba-8d44-4199-ccfc-056ff650d77c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preparation Functions and Dataset Definition**\n",
        "This cell defines functions to load and preprocess the IMDB dataset. It also defines a custom Dataset class (MovieReviewDataset) that builds a vocabulary and converts text to vector representations."
      ],
      "metadata": {
        "id": "Orb0pr85xh0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_imdb_data(num_samples=5000):\n",
        "    url = \"https://raw.githubusercontent.com/Ankit152/IMDB-sentiment-analysis/master/IMDB-Dataset.csv\"\n",
        "    df = pd.read_csv(url)\n",
        "    df = df.sample(n=min(num_samples, len(df)), random_state=42)\n",
        "    df['sentiment'] = (df['sentiment'] == 'positive').astype(int)\n",
        "    return df['review'].tolist(), df['sentiment'].tolist()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "class MovieReviewDataset(Dataset):\n",
        "    def __init__(self, texts, labels, vocab_size=5000, max_length=200, word_to_idx=None):\n",
        "        self.texts = [preprocess_text(text) for text in texts]\n",
        "        self.labels = labels\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_length = max_length\n",
        "        self.word_to_idx = word_to_idx if word_to_idx is not None else self._build_vocabulary()\n",
        "\n",
        "    def _build_vocabulary(self):\n",
        "        words = ' '.join(self.texts).split()\n",
        "        word_counts = Counter(words)\n",
        "        # Reserve two indices for <PAD> and <UNK>\n",
        "        common_words = dict(word_counts.most_common(self.vocab_size - 2))\n",
        "        word_to_idx = {word: idx + 2 for idx, word in enumerate(common_words.keys())}\n",
        "        word_to_idx['<PAD>'] = 0\n",
        "        word_to_idx['<UNK>'] = 1\n",
        "        return word_to_idx\n",
        "\n",
        "    def text_to_vector(self, text):\n",
        "        vector = torch.zeros(self.vocab_size)\n",
        "        for word in text.split()[:self.max_length]:\n",
        "            idx = self.word_to_idx.get(word, 1)  # Use 1 for unknown words\n",
        "            vector[idx] += 1\n",
        "        return vector\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        vector = self.text_to_vector(text)\n",
        "        return vector, torch.tensor(label, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "xTkEgUHNxf6q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Definition**\n",
        "\n",
        "This cell defines the neural network model (SentimentModel), which is a simple feed-forward network with dropout, ReLU activations, and a sigmoid output."
      ],
      "metadata": {
        "id": "W1OqmePqxwfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(SentimentModel, self).__init__()\n",
        "        self.layer1 = nn.Linear(vocab_size, 128)\n",
        "        self.layer2 = nn.Linear(128, 64)\n",
        "        self.layer3 = nn.Linear(64, 1)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(self.relu(self.layer1(x)))\n",
        "        x = self.dropout(self.relu(self.layer2(x)))\n",
        "        x = self.sigmoid(self.layer3(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "OlhSI4Dtx3Z3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initialize Comgra Recorder**\n",
        "\n",
        "This cell initializes the Comgra recorder. The recorder (accessed as comgra.my_recorder) is responsible for tracking training metrics such as inputs, outputs, loss, gradients, and KPIs during training."
      ],
      "metadata": {
        "id": "oxDVKgtux6DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comgra.my_recorder = ComgraRecorder(\n",
        "    comgra_root_path=\"/content\",\n",
        "    group=\"movie_sentiment_analysis\",\n",
        "    trial_id=\"imdb_trial\",  # Use a unique trial_id if you run multiple sessions\n",
        "    decision_maker_for_recordings=DecisionMakerForRecordingsFrequencyPerType(min_training_steps_difference=10),\n",
        ")"
      ],
      "metadata": {
        "id": "eVAGu6qWx_Ou"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**comgra.my_recorder:** Used throughout the training process to record batches, iterations, tensors, gradients, and KPIs."
      ],
      "metadata": {
        "id": "C3hveefmyFUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Loading, Splitting, and DataLoader Setup**\n",
        "\n",
        "This cell loads the IMDB data, splits it into training and validation sets, and creates PyTorch DataLoader objects. Notice that the training dataset builds the vocabulary which is then reused by the validation dataset."
      ],
      "metadata": {
        "id": "QJfBpRwAyMwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading IMDB dataset...\")\n",
        "texts, labels = load_imdb_data()\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create dataset instances (validation uses the training vocabulary)\n",
        "train_dataset = MovieReviewDataset(train_texts, train_labels)\n",
        "val_dataset = MovieReviewDataset(val_texts, val_labels,\n",
        "                                 vocab_size=train_dataset.vocab_size,\n",
        "                                 word_to_idx=train_dataset.word_to_idx)\n",
        "\n",
        "# Create DataLoaders for batch processing\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeVtMp9eyD1l",
        "outputId": "752a0850-7139-44d2-c40e-60299b336fab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading IMDB dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model, Loss, Optimizer Setup, and Comgra Module Tracking**\n",
        "In this cell, the model is instantiated and moved to the correct device (GPU if available). It also defines the loss function (Binary Cross Entropy) and optimizer (Adam). The model is then registered with the Comgra recorder using comgra.my_recorder.track_module."
      ],
      "metadata": {
        "id": "CucCpkLpyUzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model and move it to the selected device\n",
        "model = SentimentModel(train_dataset.vocab_size).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Register the model with Comgra for tracking\n",
        "comgra.my_recorder.track_module(\"movie_sentiment_model\", model)\n"
      ],
      "metadata": {
        "id": "m9Ny-3zFyc7q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**comgra.my_recorder.track_module:** Registers the model so that its weights and architecture are tracked during training."
      ],
      "metadata": {
        "id": "VFpcAd0XyijL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Loop with Global Step and CUDA Support**\n",
        "This cell contains the main training loop. For each batch, the Comgra recorder records inputs, outputs, loss, and gradients. A global step counter ensures that the training step increases monotonically."
      ],
      "metadata": {
        "id": "sI6MR0voyl2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "best_val_accuracy = 0\n",
        "global_step = 0  # Global counter for monotonic training steps\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        # Move data to device\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Start a new batch in Comgra with the current global step\n",
        "        comgra.my_recorder.start_batch(global_step, inputs.shape[0])\n",
        "        comgra.my_recorder.start_iteration()\n",
        "\n",
        "        # Forward pass and record tensors\n",
        "        comgra.my_recorder.register_tensor(\"inputs\", inputs, is_input=True)\n",
        "        outputs = model(inputs)\n",
        "        comgra.my_recorder.register_tensor(\"outputs\", outputs)\n",
        "        comgra.my_recorder.register_tensor(\"targets\", targets.unsqueeze(1), is_target=True)\n",
        "\n",
        "        loss = criterion(outputs, targets.unsqueeze(1))\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calculate training accuracy for the batch\n",
        "        predictions = (outputs >= 0.5).float()\n",
        "        correct_train += (predictions == targets.unsqueeze(1)).sum().item()\n",
        "        total_train += targets.size(0)\n",
        "\n",
        "        # Record the loss in Comgra\n",
        "        comgra.my_recorder.register_tensor(\"loss\", loss, is_loss=True)\n",
        "        comgra.my_recorder.record_kpi_in_graph(\"loss\", \"\", loss)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Record gradients and finish the iteration/batch\n",
        "        comgra.my_recorder.record_current_gradients(\"gradients\")\n",
        "        comgra.my_recorder.finish_iteration()\n",
        "        comgra.my_recorder.finish_batch()\n",
        "\n",
        "        global_step += 1  # Ensure the training step is monotonically increasing\n",
        "\n",
        "    # -------------------------\n",
        "    # Validation Phase\n",
        "    # -------------------------\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_loss += criterion(outputs, targets.unsqueeze(1)).item()\n",
        "            predictions = (outputs >= 0.5).float()\n",
        "            correct_val += (predictions == targets.unsqueeze(1)).sum().item()\n",
        "            total_val += targets.size(0)\n",
        "\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    val_accuracy = 100 * correct_val / total_val\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Training Loss: {avg_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%\")\n",
        "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Record KPIs using Comgra\n",
        "    comgra.my_recorder.record_kpi_in_graph(\"train_accuracy\", \"\", train_accuracy)\n",
        "    comgra.my_recorder.record_kpi_in_graph(\"val_accuracy\", \"\", val_accuracy)\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "\n",
        "# Finalize the Comgra recording session\n",
        "comgra.my_recorder.finalize()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjXC0KorygBY",
        "outputId": "9478f084-5dfd-4f4b-e65d-0e1109c770bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/comgra/recorder.py:602: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  val = tensor.std(dim=value_dimensions).unsqueeze(dim=expansion_dim)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "Training Loss: 0.5330, Training Accuracy: 74.30%\n",
            "Validation Loss: 0.4033, Validation Accuracy: 81.90%\n",
            "------------------------------------------------------------\n",
            "Epoch 2/3\n",
            "Training Loss: 0.2669, Training Accuracy: 89.78%\n",
            "Validation Loss: 0.4727, Validation Accuracy: 80.20%\n",
            "------------------------------------------------------------\n",
            "Epoch 3/3\n",
            "Training Loss: 0.1530, Training Accuracy: 94.28%\n",
            "Validation Loss: 0.4574, Validation Accuracy: 81.80%\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important Comgra Objects and Methods:\n",
        "\n",
        "1. comgra.my_recorder.start_batch / start_iteration: Begin tracking a new batch and iteration.\n",
        "2. register_tensor: Logs important tensors (inputs, outputs, targets, loss).\n",
        "3. record_current_gradients: Captures the current gradients.\n",
        "4. record_kpi_in_graph: Logs key performance indicators (e.g., loss, accuracy).\n",
        "5. finalize: Ends the recording session."
      ],
      "metadata": {
        "id": "FS19v6byyxFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Prediction and Testing**\n",
        "\n",
        "This cell defines a function to predict sentiment for new text reviews and then tests the model on a few examples."
      ],
      "metadata": {
        "id": "EoGTvSKqzHL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(model, text, dataset, device):\n",
        "    model.eval()\n",
        "    processed_text = preprocess_text(text)\n",
        "    vector = dataset.text_to_vector(processed_text)\n",
        "    vector = vector.to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(vector.unsqueeze(0))\n",
        "    probability = output.item()\n",
        "    return probability, \"Positive\" if probability >= 0.5 else \"Negative\"\n",
        "\n",
        "# Test the model on example reviews\n",
        "test_reviews = [\n",
        "    \"This movie was absolutely fantastic! Great acting and amazing plot.\",\n",
        "    \"I couldn't finish watching it. The plot was boring and the acting was terrible.\",\n",
        "]\n",
        "\n",
        "print(\"\\nTesting model on example reviews:\")\n",
        "for review in test_reviews:\n",
        "    prob, sentiment = predict_sentiment(model, review, train_dataset, device)\n",
        "    print(f\"\\nReview: {review}\")\n",
        "    print(f\"Sentiment: {sentiment} (confidence: {prob:.2%})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6rn9qmQzDI4",
        "outputId": "d36a2b2a-efc5-48a1-f24f-c3012f27e812"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing model on example reviews:\n",
            "\n",
            "Review: This movie was absolutely fantastic! Great acting and amazing plot.\n",
            "Sentiment: Positive (confidence: 82.71%)\n",
            "\n",
            "Review: I couldn't finish watching it. The plot was boring and the acting was terrible.\n",
            "Sentiment: Negative (confidence: 11.39%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Launch the Comgra Server**\n",
        "\n",
        "This final cell launches the Comgra server in the background and displays it using an iframe (ideal for Google Colab)."
      ],
      "metadata": {
        "id": "XzC6xAQazPai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "server_command = [\"comgra\", \"--path\", \"/content/movie_sentiment_analysis\"]\n",
        "server_process = subprocess.Popen(server_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "time.sleep(2)\n",
        "print(\"\\nServer started in the background\")\n",
        "\n",
        "def display_server(port):\n",
        "    script = f\"\"\"\n",
        "    <script>\n",
        "    (async () => {{\n",
        "        const url = await google.colab.kernel.proxyPort({port});\n",
        "        const iframe = document.createElement('iframe');\n",
        "        iframe.src = url;\n",
        "        iframe.width = '1400px';\n",
        "        iframe.height = '1200px';\n",
        "        iframe.frameBorder = 0;\n",
        "        document.body.appendChild(iframe);\n",
        "    }})();\n",
        "    </script>\n",
        "    \"\"\"\n",
        "    display(HTML(script))\n",
        "\n",
        "display_server(8055)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-rGvSE7RzTdn",
        "outputId": "4c8ac229-d918-4a8e-eb45-e5c1879383f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Server started in the background\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <script>\n",
              "    (async () => {\n",
              "        const url = await google.colab.kernel.proxyPort(8055);\n",
              "        const iframe = document.createElement('iframe');\n",
              "        iframe.src = url;\n",
              "        iframe.width = '1400px';\n",
              "        iframe.height = '1200px';\n",
              "        iframe.frameBorder = 0;\n",
              "        document.body.appendChild(iframe);\n",
              "    })();\n",
              "    </script>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comgra Server:** Although not directly part of comgra.my_recorder, launching the server allows you to visualize all the recorded metrics and KPIs via the Comgra dashboard."
      ],
      "metadata": {
        "id": "EkMAKC7YzXkn"
      }
    }
  ]
}